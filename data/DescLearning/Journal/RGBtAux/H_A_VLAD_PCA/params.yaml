batch_size: 25
curr_epoch: 0
lr_scheduler:
  main_trainer:
    class: lr_scheduler.MultiStepLR
    param:
      gamma: 0.5
      milestones: [15, 25, 30]
max_epoch: 50
min_value_to_stop: 20
num_workers: 8
saved_files: {best_network: best_network.pth, loss: loss.pth, network_Fuse: network_Fuse.pth,
  network_FusePCA: network_FusePCA.pth, network_Hall: network_Hall.pth, network_Main: network_Main.pth,
  optimizer_main_trainer: optimizer_main_trainer.pth, val_score: val_score.pth}
score_file: score_file.pth
shuffle: true
sucess_bad_epoch: 2
testing_mod: [rgb]
training_mod: [rgb, mono_depth]
